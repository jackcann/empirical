{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb1b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670ea309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " webscraping Premier League\n",
      "Scraped Premier League 2025\n",
      "Scraped Premier League 2024\n",
      "Scraped Premier League 2023\n",
      "Scraped Premier League 2022\n",
      "Scraped Premier League 2021\n",
      "Scraped Premier League 2020\n",
      "Scraped Premier League 2019\n",
      "Scraped Premier League 2018\n",
      "Scraped Premier League 2017\n",
      "Scraped Premier League 2016\n",
      "Scraped Premier League 2015\n",
      "Scraped Premier League 2014\n",
      "Scraped Premier League 2013\n",
      "Scraped Premier League 2012\n",
      "Scraped Premier League 2011\n",
      "\n",
      " webscraping La Liga\n",
      "Scraped La Liga 2025\n",
      "Scraped La Liga 2024\n",
      "Scraped La Liga 2023\n",
      "Scraped La Liga 2022\n",
      "Scraped La Liga 2021\n",
      "Scraped La Liga 2020\n",
      "Scraped La Liga 2019\n",
      "Scraped La Liga 2018\n",
      "Scraped La Liga 2017\n",
      "Scraped La Liga 2016\n",
      "Scraped La Liga 2015\n",
      "Scraped La Liga 2014\n",
      "Scraped La Liga 2013\n",
      "Scraped La Liga 2012\n",
      "Scraped La Liga 2011\n",
      "\n",
      " webscraping Serie A\n",
      "Scraped Serie A 2025\n",
      "Scraped Serie A 2024\n",
      "Scraped Serie A 2023\n",
      "Scraped Serie A 2022\n",
      "Scraped Serie A 2021\n",
      "Scraped Serie A 2020\n",
      "Scraped Serie A 2019\n",
      "Scraped Serie A 2018\n",
      "Scraped Serie A 2017\n",
      "Scraped Serie A 2016\n",
      "Scraped Serie A 2015\n",
      "Scraped Serie A 2014\n",
      "Scraped Serie A 2013\n",
      "Scraped Serie A 2012\n",
      "Scraped Serie A 2011\n",
      "\n",
      " webscraping Bundesliga\n",
      "Scraped Bundesliga 2025\n",
      "Scraped Bundesliga 2024\n",
      "Scraped Bundesliga 2023\n",
      "Scraped Bundesliga 2022\n",
      "Scraped Bundesliga 2021\n",
      "Scraped Bundesliga 2020\n",
      "Scraped Bundesliga 2019\n",
      "Scraped Bundesliga 2018\n",
      "Scraped Bundesliga 2017\n",
      "Scraped Bundesliga 2016\n",
      "Scraped Bundesliga 2015\n",
      "Scraped Bundesliga 2014\n",
      "Scraped Bundesliga 2013\n",
      "Scraped Bundesliga 2012\n",
      "Scraped Bundesliga 2011\n",
      "\n",
      " webscraping Ligue 1\n",
      "Scraped Ligue 1 2025\n",
      "Scraped Ligue 1 2024\n",
      "Scraped Ligue 1 2023\n",
      "Scraped Ligue 1 2022\n",
      "Scraped Ligue 1 2021\n",
      "Scraped Ligue 1 2020\n",
      "Scraped Ligue 1 2019\n",
      "Scraped Ligue 1 2018\n",
      "Scraped Ligue 1 2017\n",
      "Scraped Ligue 1 2016\n",
      "Scraped Ligue 1 2015\n",
      "Scraped Ligue 1 2014\n",
      "Scraped Ligue 1 2013\n",
      "Scraped Ligue 1 2012\n",
      "Scraped Ligue 1 2011\n",
      "\n",
      " Data saved\n"
     ]
    }
   ],
   "source": [
    "urls={'Premier League': 'https://fbref.com/en/comps/9/history/Premier-League-Seasons',\n",
    "    'La Liga': 'https://fbref.com/en/comps/12/history/La-Liga-Seasons',\n",
    "    'Serie A': 'https://fbref.com/en/comps/11/history/Serie-A-Seasons',\n",
    "    'Bundesliga': 'https://fbref.com/en/comps/20/history/Bundesliga-Seasons',\n",
    "    'Ligue 1': 'https://fbref.com/en/comps/13/history/Ligue-1-Seasons'}\n",
    "\n",
    "#This function gets the urls for each season from the history page\n",
    "def get_urls(history_url, season_number=15):\n",
    "    page=requests.get(history_url)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    table=soup.find('table')\n",
    "    urls=[]\n",
    "    \n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        first_cell=row.find('th')\n",
    "        if first_cell and first_cell.find('a'):\n",
    "            link=first_cell.find('a')['href']\n",
    "            full_link='https://fbref.com'+link\n",
    "            urls.append(full_link)\n",
    "    \n",
    "    return urls[:season_number]\n",
    "\n",
    "#This list stores all the data retrieved\n",
    "all_data=[]\n",
    "\n",
    "#Starts from most recent season in order to later count down\n",
    "starting_year=2025\n",
    "\n",
    "for league, history_url in urls.items():\n",
    "    print(f\"\\n webscraping {league}\")\n",
    "    \n",
    "    urls=get_urls(history_url)\n",
    "    year=starting_year\n",
    "    \n",
    "    for season_url in urls:\n",
    "        try:\n",
    "            tables=pd.read_html(season_url)\n",
    "            league_table=tables[0]\n",
    "            time.sleep(random.randint(4, 8))\n",
    "\n",
    "            #Organise table\n",
    "            league_table2=league_table[['Rk', 'Squad', 'Pts', 'MP', 'Pts/MP',\n",
    "                                        'W', 'D', 'L']]\n",
    "            league_table2.columns=['Position', 'Team', 'Points', \n",
    "                                    'Matches Played', 'Points per Match',\n",
    "                                   'Wins', 'Draws', 'Losses']\n",
    "            league_table2=league_table2.dropna()\n",
    "\n",
    "            #Create league table and season year\n",
    "            league_table2['League']=league\n",
    "            league_table2['Season']=year\n",
    "\n",
    "            #Format columns\n",
    "            league_table2=league_table2[['League', 'Season', 'Position',\n",
    "                                         'Team', 'Points', 'Matches Played', \n",
    "                                         'Points per Match', 'Wins', 'Draws', 'Losses']]\n",
    "\n",
    "            all_data.append(league_table2)\n",
    "\n",
    "            print(f\"Scraped {league} {year}\")\n",
    "            #Count down the seasons\n",
    "            year-=1 \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {league} {year}: {e}\")\n",
    "\n",
    "\n",
    "#Put into one dataframe\n",
    "combined_df=pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "#Create CSV\n",
    "combined_df.to_csv('data.csv', index=False)\n",
    "\n",
    "print(\"\\n Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1175c7ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m25\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0a583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
